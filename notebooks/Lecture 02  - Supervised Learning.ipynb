{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60c3a8f-c38d-4ff0-b6c2-e146c9702ad7",
   "metadata": {},
   "source": [
    "# Lecture 2: Supervised Learning\n",
    "\n",
    "COMP 3921F <br>\n",
    "Applied Machine Learning <br>\n",
    "Mon 4:40 PM - 5:55 PM <br>\n",
    "Tue: 5:00 PM - 6:15 PM\n",
    "\n",
    "Professor: __Ramesh Natarajan__<br>\n",
    "Email: **ramesh.natarajan@yu.edu**<br>\n",
    "Department of Computer Science<br>\n",
    "Stern College and Yeshiva University\n",
    "\n",
    "Date: Jan 24, 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386a23e-150b-4345-b710-d0f952fae87b",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "1. The starting point for developing the notebook-based instruction material was the set of notebooks provided by the previous  course instructor__[Prof. Zach Glassman](https://www.linkedin.com/in/zachary-glassman-7088844b/)__.\n",
    "2. These notebooks have been augmented by similar instruction material taken from many, many other sources, including official documentation from many ML libraries and frameworks. I have adapted and modified the content where needed to make it compatible with student level, orientation and proficiency in this course.\n",
    "3. The primary addition sources include:\n",
    "   1. Course content from V. Kuleshov, Cornell Tech __[repo](https://github.com/kuleshov/cornell-cs5785-2020-applied-ml/blob/main/notebooks/lecture1-introduction.ipynb)__.\n",
    "   2. Book and support material from Hal Daume II, __[A course in Machine Learning](http://ciml.info)__. __[repo](https://github.com/hal3/ciml/)__\n",
    "   3. Book and support material from A. Geron, __[Hands-On Machine Learning with Scikit-Learn, Keras and Tensorflow (3rd edition)](https://homl.info/er3)__. __[repo](https://github.com/ageron/handson-ml3/blob/main/README.md)__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cf1c2-cf4f-4256-9965-fe70caf82ef3",
   "metadata": {},
   "source": [
    "# Announcements\n",
    "\n",
    "1. Problem Set 1 in progress.\n",
    "2. Recitations will review __[differential calculus](https://github.com/ageron/handson-ml2/blob/master/math_differential_calculus.ipynb)__ and __[linear algebra](https://github.com/ageron/handson-ml2/blob/master/math_linear_algebra.ipynb)__.\n",
    "3. You should continue  to review and refresh yourself on the mathematical prerequisites for applied machine learning from part 1 for Deisenroth, Faisal and Ong, __[Mathematics for Machine Learning](https://mml-book.github.io/book/mml-book.pdf)__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa33fdf-f236-4d65-9925-9d72044bfb29",
   "metadata": {},
   "source": [
    "# Definition of Supervised Learning\n",
    "\n",
    "A machine learning problem has 3 ingredients:\n",
    "\n",
    "+  A task **T** with an outcome **y** (e.g. - predict the user rating for any movie in the set of movies in a online database)\n",
    "+  A set of training examples **E** with each example containing the  relevant context **X** for this task (e.g. viewer history, known preferences, movie attributes etc.), along with task outcome **y** (e.g.the  user rating observed in this context **X**).  \n",
    "+ One or more performance metrics **P** for the task (e.g. - how accurate are the machine learning predictions?)\n",
    "\n",
    "For supervised learning the task **T** usually involves predicting a label. Hence,  the experiences consist  of context-dependent labelled examples, and the performance metric **P** is the label prediction accuracy on unseen examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8bc5b-22c9-48a8-8d67-71f844c4891a",
   "metadata": {},
   "source": [
    "# Mathematical Statement of Supervised Learning\n",
    "\n",
    "We seek a model  $f_{\\theta} : X → Y$ , where $X$ and $Y$ are input and output spaces respectively, and $\\theta$ is a set of unknown model parameters, which are estimated from given a set of labeled training examples $\\{x_i , y_i\\}_{i=1}^n$ with each example consisting of inputs $x_i \\in X$ and outputs $y_i \\in Y$.\n",
    "\n",
    "Examples:\n",
    "\n",
    "$X$ may be the space of pixelated  images and $Y$ may be an object in the image\n",
    "$X$ may be the space of movie reviews  and $Y$ may be the space of movie ratings\n",
    "$X$ may be patient medical history and $Y$ may be the space of diagnosable illnesses\n",
    "$X$ may be the space of history sequences and $Y$ may be the space of the next element of this sequence \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072444d-a36f-4665-908b-b635cab68f01",
   "metadata": {},
   "source": [
    "# Supervised Learning Dataset\n",
    "\n",
    "A dataset for supervised learning consists of a set of  $n$ examples (e.g., $n$ rows or records).\n",
    "\n",
    "Training data = $\\mathcal{D} = \\{(x^{(i)}, y^{(i)}) \\mid i = 1,2,...,n\\}$\n",
    "\n",
    "Here $x^{(i)}$ denotes the individual input features for example  $i$, and each $y^{(i)} \\in \\mathcal{Y}$ is the corresponding target\n",
    "\n",
    "Therefore, $(x^{(i)}, y^{(i)})$ is the $i$'th *example* in the training data. \n",
    "\n",
    "More precisely, an input $x^{(i)} \\in \\mathcal{X}$ is a (transposed) $d$-dimensional vector of the form\n",
    "$$ x^{(i)} = \\begin{bmatrix}\n",
    "x^{(i)}_1, \n",
    "x^{(i)}_2,\n",
    "\\ldots, x^{(i)}_d\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The set $\\mathcal{X}$ is called the feature space. \n",
    "\n",
    "In supervised learning, the examples $\\{(x^{(i)}, y^{(i)}) \\mid i = 1,2,...,n\\}$ are usually assumed to be independent unless stated otherwise; therefore the order of the examples is not important, and the data may often be shuffled before modeling to avoid any model training bias from the initial or presented ordering\n",
    "\n",
    "These concepts are illustrated using the diabetes data set from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425b650b-2318-41b2-8787-81b3e764ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and set defaults\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dd54e-d581-487d-9998-8ff827cbf597",
   "metadata": {},
   "source": [
    "## Load diabetes dataset and print the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3386c-6be2-41fd-ae81-161424a8765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "print(diabetes.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b393b1-2c59-4806-a486-b16326d73547",
   "metadata": {},
   "source": [
    "# Input and Target features\n",
    "\n",
    "As can be seen this data set consists of input (or raw) features, and corresponding targets.  Occasionally the input data may have already undergone some pre-processing and data cleaning, but most often these steps may have to be performed before any machine learning is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f7a62-35c1-4b9e-a512-3eb923f76165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diabetes_X, diabetes_y = diabetes.data, diabetes.target\n",
    "\n",
    "# Print part of the dataset\n",
    "print(\"Input Features\")\n",
    "display(diabetes_X.head())\n",
    "\n",
    "print(\"Target Feature\")\n",
    "display(diabetes_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434678d1-1758-4848-b464-1dff407ede65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let see the feature space for patient i = 0 and i = 10 (note that these are pre-normalized to have mean 0, sd = 1)\n",
    "\n",
    "for i in [0,10]:\n",
    "    print(f\"patient {i} features:\\n  {diabetes_X.iloc[i].to_frame().T}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad202b5b-f4d4-498d-9ad5-fcf3e4321dcb",
   "metadata": {},
   "source": [
    "# Features: Discrete vs. Continuous \n",
    "\n",
    "Features can be either discrete (values in an unordered finite set, e.g. gender)  or continuous (numerical either integer or real)\n",
    "\n",
    "Note that sex in this dataset has been coded as a continuous feature (which is generally not an issue if the feature is binary, but would be incorrect for a multivalued discrete feature).\n",
    "\n",
    "Its always a great idea to  plot the univariate distributions of each feature, and the computation time can be reduced by sampling the data set if it is too large.\n",
    "\n",
    "Note that for this data set the input features appear to have been pre-normalized to mean 0 and std dev 1 (as already mentioned in the metadata prinited above).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bff522-2a00-4903-acb3-bf42812cb749",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preparation\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>Preprocessing</li>\n",
    "    <ul>\n",
    "    <li>Data quality and anomalous values missing data imputation </li>\n",
    "    <li>Missing data imputation </li>\n",
    "    <li>Normalization</li>\n",
    "    <li>Binning </li>\n",
    "    <li>One-hot encoding</li>\n",
    "    <li>Helmert and Orthogonal Polynomial coding</li>\n",
    "    <li>Categorical clustering (zip codes)</li>\n",
    "    <li>High-dimensional/sparse embeddings (text)</li>\n",
    "    </ul>\n",
    "<li>Feature elimination</li>\n",
    "    <ul>\n",
    "    <li>Information gain and partial info gain</li>\n",
    "    <li>Correlation and partial correlation</li>\n",
    "    </ul>\n",
    "<li>Feature Leakage</li>\n",
    "<li>Feature Anomaly Detection</li>\n",
    "<li>Unbalanced Datasets</li>\n",
    "<li>Positive-only targets</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec111096-ba01-47d2-ae45-61c1b2fc3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X.hist( bins=30, figsize=(15, 10))\n",
    "plt.suptitle(\"Feature Histograms\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c92fae-497c-4ede-bf44-7de9d304e6c7",
   "metadata": {},
   "source": [
    "# Training Dataset: Creating derived features\n",
    "\n",
    "We can transform the existing feature in various ways to create new **derived features** (as opposed to the original raw or input features provided in the dataset. \n",
    "\n",
    "These derived features may only involve a single input features, but more generally they can involve multiple input features such as the case described below, where we introduce a flag for risky patients (here \"older females\" and \"high BMI older male\")\n",
    "\n",
    "* Is the patient old and female? (e.g. useful if female are somehow at risk).\n",
    "* Is the patient old, male, with BMI above the  threshold? (e.g. useful if high BMI males are somehow at risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be1c0e-21f0-4afb-8541-11fbfd9eef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X['at-risk female'] = (diabetes_X['sex'] < 0) & (diabetes_X['age'] > 0.05)\n",
    "diabetes_X['at-risk male'] = (diabetes_X['sex'] > 0) & (diabetes_X['age'] > 0.05) & (diabetes_X['bmi'] > 0.05)\n",
    "diabetes_X[['age','sex', 'at-risk female', 'at-risk male']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317a5c3-e088-4f84-b071-fda91f239281",
   "metadata": {},
   "source": [
    "# Plotting the distribution of the target variable\n",
    "\n",
    "It is helpful to plot the target variable to see if there are any outliers, and to understand if it is discrete or continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e8499-3beb-48a1-af28-7237dabe22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Diabetes risk score')\n",
    "plt.ylabel('Number of patients')\n",
    "diabetes_y.hist(figsize = (5,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0aba4-e668-4f37-b6ed-8980722d32b4",
   "metadata": {},
   "source": [
    "# Splitting data into training and test datasets\n",
    "\n",
    "In general, we should also use a completely unseen validation data set that is only used after all the model training and evaluation steps are completed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b107725-0098-49cc-8062-6fc9fa7fd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the BMI feature\n",
    "diabetes_X = diabetes_X.loc[:, ['bmi']]\n",
    "\n",
    "# The BMI is zero-centered and normalized; we unnormalize it for ease of presentation\n",
    "diabetes_X = diabetes_X * 30 + 25\n",
    "\n",
    "n_train = 40\n",
    "# Collect 20 data points\n",
    "diabetes_X_train = diabetes_X.iloc[-n_train :]\n",
    "diabetes_y_train = diabetes_y.iloc[-n_train :]\n",
    "\n",
    "# Display some of the data points\n",
    "pd.concat([diabetes_X_train, diabetes_y_train], axis=1).head()\n",
    "\n",
    "n_test = 5\n",
    "# Collect 3 data points\n",
    "diabetes_X_test = diabetes_X.iloc[:n_test]\n",
    "diabetes_y_test = diabetes_y.iloc[:n_test]\n",
    "\n",
    "plt.scatter(diabetes_X_train, diabetes_y_train)\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')\n",
    "plt.xlabel('Body Mass Index (BMI)')\n",
    "plt.ylabel('Diabetes Risk')\n",
    "plt.legend(['training data', 'test data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b563aa-ee98-44f2-a4da-b15ad11a64c0",
   "metadata": {},
   "source": [
    "# Targets: Regression vs. Classification\n",
    "\n",
    "Supervised learning algorithms differ in the form of the target variable.\n",
    "\n",
    "1. __Regression__: The target variable $y$ is continuous and we are trying to predict its value  \n",
    "2. __Classification__: The target variable $y$ is discrete. Each discrete value is a distinct *class* and we are trying to predict the class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896df11d-e50f-49f9-99fd-d4889de7f03d",
   "metadata": {},
   "source": [
    "# Examples of Supervised Learning Methods\n",
    "\n",
    "<table><tr>\n",
    "</td width=\"30%\">\n",
    "    <td><center>\n",
    "        <img src=\"../img/Lecture 2/supervised learning creative.png\"/>    \n",
    "    </center>\n",
    "    Generated by Chat-GPT \n",
    "     </td>  \n",
    "    <td>\n",
    "<ul>\n",
    "<font size = \"+1\">\n",
    "<li>Decision Trees</li>\n",
    "<li>Linear Models</li>\n",
    "<li>Discriminant Analysis</li>\n",
    "<li>Kernel Regression</li>\n",
    "<li>Support Vector Machines</li>\n",
    "<li>Nearest Neighbors</li>\n",
    "<li>Gaussian Processes</li>\n",
    "<li>Ensembles (Boosting, Bagging, Random Forests)</li>\n",
    "<li>Neural Networks</li>\n",
    "</fontsize>font>\n",
    "</ul>\n",
    "\n",
    "</tr></table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec5a6c-ee7e-4d25-bc7a-76a54e103c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a continous target using linear regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train.values)\n",
    "\n",
    "# Make predictions on the training set\n",
    "diabetes_y_train_pred = regr.predict(diabetes_X_train)\n",
    "\n",
    "# generate predictions on the test set\n",
    "diabetes_y_test_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# visualize the results\n",
    "\n",
    "plt.xlabel('Body Mass Index (BMI)')\n",
    "plt.ylabel('Diabetes Risk')\n",
    "plt.scatter(diabetes_X_train.loc[:, ['bmi']], diabetes_y_train)\n",
    "plt.scatter(diabetes_X_test.loc[:, ['bmi']], diabetes_y_test, color='red', marker='o')\n",
    "plt.scatter(diabetes_X_train.loc[:, ['bmi']], diabetes_y_train_pred, marker='x',color='black')\n",
    "plt.plot(diabetes_X_test.loc[:, ['bmi']], diabetes_y_test_pred, 'x', color='red', mew=3, markersize=8)\n",
    "plt.legend([ 'Train', 'Test', 'Train Predict', 'Test Predict',])\n",
    "plt.show()\n",
    "\n",
    "print('Training set mean squared error: %.2f'\n",
    "      % mean_squared_error(diabetes_y_train, diabetes_y_train_pred))\n",
    "print('Test set mean squared error: %.2f'\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d45a12-eeb0-4f4f-9107-f7003be8e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize the targets in 2 bins low (0), high(1)\n",
    "diabetes_y_train_discr = np.digitize(diabetes_y_train, bins=[150]) # splits values at threshold 150\n",
    "diabetes_y_test_discr = np.digitize(diabetes_y_test, bins=[150]) # splits values at threshold 150\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(diabetes_X_train[diabetes_y_train_discr==0], diabetes_y_train[diabetes_y_train_discr==0], marker='o', s=80, facecolors='none', edgecolors='g')\n",
    "plt.scatter(diabetes_X_train[diabetes_y_train_discr==1], diabetes_y_train[diabetes_y_train_discr==1], marker='o', s=80, facecolors='none', edgecolors='r')\n",
    "plt.scatter(diabetes_X_test[diabetes_y_test_discr==0], diabetes_y_test[diabetes_y_test_discr==0], marker='o', s=80, facecolors='g', edgecolors='g')\n",
    "plt.scatter(diabetes_X_test[diabetes_y_test_discr==1], diabetes_y_test[diabetes_y_test_discr==1], marker='o', s=80, facecolors='r', edgecolors='r')\n",
    "\n",
    "plt.legend(['Low-Risk Patients (train)', 'High-Risk Patients (train)','Low-Risk Patients (test)', 'High-Risk Patients (test)'])\n",
    "plt.title('High-Risk and Low_Risk patients (with discretization) based on target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84760f54-37ec-4c45-bc51-6d30d14e4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object for the discretized data\n",
    "regr2 = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr2.fit(diabetes_X_train, diabetes_y_train_discr)\n",
    "\n",
    "# Make predictions on the training set\n",
    "diabetes_y_train_discr_pred = np.digitize(regr2.predict(diabetes_X_train), bins=[0.5])\n",
    "\n",
    "# # generate predictions on the test set\n",
    "diabetes_y_test_discr_pred = np.digitize(regr.predict(diabetes_X_test), bins=[0.5])\n",
    "\n",
    "# visualize the results\n",
    "\n",
    "plt.xlabel('Body Mass Index (BMI)')\n",
    "plt.ylabel('Diabetes Risk (High, Low)')\n",
    "plt.scatter(diabetes_X_train.loc[:, ['bmi']], diabetes_y_train_discr, marker='o')\n",
    "plt.scatter(diabetes_X_test.loc[:, ['bmi']], diabetes_y_test_discr, marker='o', color='red')\n",
    "plt.scatter(diabetes_X_train.loc[:, ['bmi']], diabetes_y_train_discr_pred, color='black', marker='x')\n",
    "plt.plot(diabetes_X_test.loc[:, ['bmi']], diabetes_y_test_discr_pred, 'x', color='red', mew=3, markersize=8)\n",
    "\n",
    "plt.legend(['Train', 'Test', 'Train Predict', 'Test Predict'])\n",
    "plt.show()\n",
    "\n",
    "print('Training set mean squared error: %.2f'\n",
    "      % mean_squared_error(diabetes_y_train_discr, diabetes_y_train_discr_pred))\n",
    "print('Test set mean squared error: %.2f'\n",
    "      % mean_squared_error(diabetes_y_test_discr, diabetes_y_test_discr_pred))\n",
    "\n",
    "# this is the same as the average number of misclassifications\n",
    "\n",
    "print('Training set mean absolute error: %.2f'\n",
    "      % mean_absolute_error(diabetes_y_train_discr, diabetes_y_train_discr_pred))\n",
    "print('Test set mean absolute error: %.2f'\n",
    "      % mean_absolute_error(diabetes_y_test_discr, diabetes_y_test_discr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f1b3d-b27b-471f-b39a-89ca4f07f9ba",
   "metadata": {},
   "source": [
    "# Model Perfomance Metrics\n",
    "\n",
    "<ul>\n",
    "<li>Classification metrics</li>\n",
    "    <ul>\n",
    "    <li>Binary and Multiclass accuracy </li>\n",
    "    <li>Confusion Matrix</li>\n",
    "    <li>Gain Charts, ROC, AUC.</li>\n",
    "    <li>Model calibration metrics</li>\n",
    "    </ul>        \n",
    "<li>Regression metrics</li>\n",
    "    <ul>\n",
    "    <li>Absolute metrics (MSE, MAD)</li>\n",
    "    <li>Relative metrics (MAPE)</li>\n",
    "    <li>R-squared, Mallows Cp</li>\n",
    "    </ul>  \n",
    "<li>Ranking metrics</li>\n",
    "    <ul> \n",
    "    <li>Precision at k</li>\n",
    "    <li>Mean Reciprocal rank</li>\n",
    "    <li>Normalized Discounted Cumulative Gain</li>\n",
    "    <li>Spearman’s rank correlation</li>\n",
    "    </ul>   \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381140eb-dc4d-4e56-bc39-b9df96958888",
   "metadata": {},
   "source": [
    "# Issues in Supervised Learning\n",
    "\n",
    "+ Can unlabeled data be used for unsupervised learning?\n",
    "+ Can we transfer model details from one task to another related but different task?\n",
    "What is the relationship between different learning algorithms and models?  How do we know which to use when?\n",
    "+ How do we explain the model predictions? Global interpretability and per-example explainability.\n",
    "+Can a learning algorithm also suggest where new example data must be collected to improve model quality - e.g. guided exploration?  \n",
    "+ Can we have data privacy for sensitive data (e.g. healthcare, finance) without compromising model quality?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375060a-8dc1-4d58-b387-18854b320f5b",
   "metadata": {},
   "source": [
    "# Summary \n",
    "The primary application of supervised learning has been in prediction.  \n",
    "\n",
    "In the past the structure of the models was of little importance as long as the models performed well in practice.   More recently there is quite a bit of interest in **model explainability** (for the overall model, as well as for individual model predictions).   \n",
    "\n",
    "Finally, there is also considerable interest in understanding the reliability and robustness of individual predictions (termed **uncertainty quantification**).  For individual predictions this is determined by the nature of the response function, as well as by the amount of training data that the model has access to in the relevant parts of the input data space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
