{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a61bea4-1d0b-4b97-9c29-c4db350d4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1fd1f-c28b-4e21-a4eb-fa98ab1d015c",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. Make sure you have filled out your \"NAME\" and \"COLLABORATORS\" (if any) in the previous cell.\n",
    "\n",
    "2. You should complete all code/markdown cells that state \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\". \n",
    "   \n",
    "3. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "4. Partial credit can be obtained if your solution approach is clear and the documented within comments in the implementation.\n",
    "\n",
    "5. You should follow good coding practices. Your code should use type hints, be robust against invalid inputs, and you should also write a few test cases to check for correctness particularly including edge cases.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e64a0-6a08-4c69-84d3-22c5173488d4",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "In this homework, we will build a few models from scratch and then use them to explore a real world dataset.  We are hoping to get some insight into the following topics:\n",
    "\n",
    "1. How does the training process work?\n",
    "2. What is the flow for the prediction process?\n",
    "3. What does a model even look like?\n",
    "\n",
    "Most machine learning libraries or packages will make some assumptions about the input and output format of the data.  Here we will also standardize on a format which is inspired by one such library.\n",
    "\n",
    "We will assume that our data is structured as a dataframe with a special column called \"label\" for the classification target.  So for a problem with two features, it might look like:\n",
    "\n",
    "|Feature 1|Feature 2|label|\n",
    "|---|---|---|\n",
    "|$x_{0,0}$|$x_{0,1}$|$y_{0}$|\n",
    "|$x_{1,0}$|$x_{1,1}$|$y_{1}$|\n",
    "|$\\vdots$|$\\vdots$|$\\vdots$|\n",
    "|$x_{n,0}$|$x_{n,1}$|$y_{n}$|\n",
    "\n",
    "Please make sure that your code is passing all the `assert` statements before you move onto the next part. Do not assume however, that the `assert` statements will catch all cases, you will need to do your own testing as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd1516-f207-4b67-b7cb-d835c0c4f724",
   "metadata": {},
   "source": [
    "# Problem 1  - Train a decision Tree\n",
    "\n",
    "We start with building a decision tree classifier and implement both the training and inference.  As this is our first machine learning algorithm, we will take it slow and build it in many small steps and then put it all together.\n",
    "\n",
    "Our goal will be to build up a decision tree model using a variant of the C4.5 algorithm. This algorithm is an extension of the ID3 algorithm and solves many of the limitations of that algorithm. \n",
    "\n",
    "For more materials on this algorithm, please peruse\n",
    "\n",
    "- https://en.wikipedia.org/wiki/C4.5_algorithm\n",
    "\n",
    "\n",
    "The first few parts of this algorithm will be to build up a decision tree training algorithm, the second parts are to explore what to do with it.\n",
    "\n",
    "The algorithm proceeds as follows:\n",
    "\n",
    "1. Start with a dataset.  \n",
    "2. Check base cases\n",
    "3. Choose the splitting criteria which maximizes gain ratio (i.e. which feature for which you want to split)\n",
    "4. Split the dataset on this critera and recurse on each split\n",
    "\n",
    "For simplicity, we will consider two base cases:\n",
    "\n",
    "1. If all the samples have the same label\n",
    "2. If there are no features in the dataframe (this would happen as a result of recursion)\n",
    "\n",
    "Lets start by building up some of the helper functions which we will need as part of the algorithm.\n",
    "\n",
    "# Part a)\n",
    "\n",
    "First we will need to define a function to compute the entropy of a numeric pandas series. we define entropy as \n",
    "\n",
    "$$ \\sum_i - p_i \\ln_2(p_i)$$\n",
    "\n",
    "For the case of a dataset, the probably of each element occuring can be calculated from the training data quite easily. \n",
    "\n",
    "\n",
    "For the sake of checking your initial answers please use the following dataset for all the assertions.  Please do not change this dataset or you might not be able to check your assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac478fc-f863-4ff6-8d98-d278d9b4b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trial_df = pd.DataFrame({\n",
    "    'a': [1, 2, 3, 4, 2],\n",
    "    'b': ['cat', 'dog', 'cat', 'dog', 'lion'],\n",
    "    'label': [True, False, True, False, True]\n",
    "})\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb4d7c-535c-4fc0-a5d5-142ae24fee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy so we can use the almost equal method\n",
    "import numpy as np\n",
    "def assert_almost_equal(a, b):\n",
    "    \"\"\"assert almost equal with readable error message\"\"\"\n",
    "    assert np.isclose(a, b), f\"{a} != {b}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fc82e-05e1-4c74-8325-f5bf98dd164a",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6aabfde25b8bed6a6051207d4c41707f",
     "grade": false,
     "grade_id": "cell-91a03164810e3c3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy(s: pd.Series) -> float:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b13dc-998a-4447-90c7-aa719088e239",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a143345b2440c03ad6623624a7edcac3",
     "grade": true,
     "grade_id": "cell-a78390042976f4be",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(entropy(trial_df['a']), 1.9219280948873623)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eda45e-1cbe-46b3-aece-012e9a1c3785",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "Now we consider the gain, which you can think of as the information that you gain from making a decision for a particular variable.  Intuitively, we want to choose the variable to make a split which will give us the most information once we choose.  In order to do this, we look at the difference in entropy between the full problem and the subset of the problem which would occur if we take a particular value as a given. \n",
    "\n",
    "Mathematically, we can represent this as\n",
    "\n",
    "$$ G(D, ele) = H(D) - \\sum P(D|ele)H(D|ele)$$\n",
    "where $H$ is entropy $D$ is the dataset and $(D|ele)$ is the dataset given a chosen element.\n",
    "\n",
    "Please define a function `gain(df, ele, label_key)` which computes the gain of column `ele` in dataframe `df` where the label column name is given as `label_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61273416-2db7-4714-ab6b-de5f92a46c7a",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad803a31de7a766f66e4dc970ec5879b",
     "grade": false,
     "grade_id": "cell-331f2f6f582a3f83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gain(df: pd.DataFrame, ele: str, label_key: str) -> float:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340dcef-dcca-4950-8fa2-797bb570bfa1",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35b1ef0b44da84ecd67f693310048ab2",
     "grade": true,
     "grade_id": "cell-7a003b2e429b3c47",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(gain(trial_df, 'b', 'label'), 0.9709505944546686)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcf50b-965a-4e97-8b60-aa05ce257f6a",
   "metadata": {},
   "source": [
    "## Part C)\n",
    "\n",
    "Now we can compute the gain ratio for a dataframe.  The gain ratio is defined as \n",
    "\n",
    "$$ GR = \\frac{G}{SI}$$\n",
    "\n",
    "Where $SI$ is the split information defined as \n",
    "$$ -\\sum_i \\frac{N_i}{|N|}\\log_2\\left(\\frac{N_i}{|N|}\\right)$$\n",
    "where $N_i$ is the number of occurencies of a unique value for a particular element and $|N|$ is the total number of elements in that dataset.\n",
    "\n",
    "In other words, I have a dataset like \n",
    "\n",
    "|Color of Shirt|\n",
    "|--------|\n",
    "| red|\n",
    "|blue|\n",
    "|red|\n",
    "|blue|\n",
    "|blue|\n",
    "\n",
    "Then the split info would be computed as \n",
    "\n",
    "$$ SI(\\text{Color of Shirt}) = -\\left[\\frac{N_{red}}{|N|}\\log_2\\left(\\frac{N_{red}}{|N|}\\right) + \\frac{N_{blue}}{|N|}\\log_2\\left(\\frac{N_{blue}}{|N|}\\right)\\right] = - \\left[\\frac{2}{5}\\log_2\\left(\\frac{2}{5}\\right) + \\frac{3}{5}\\log_2\\left(\\frac{3}{5}\\right)\\right]\\approx 0.971$$\n",
    "\n",
    "Please feel free to leverage the following resources:\n",
    "\n",
    "- https://machinewithdata.com/2018/07/10/how-to-calculate-gain-ratio/\n",
    "\n",
    "Please define a function `gain_ratio(df, ele, label_key)` which computes the gain ratio of column `ele` in dataframe `df` where the label column name is given as `label_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1101f1-f7ca-48a0-be00-95cbc064e4c2",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a5f3ede4e442f57b8ba9535be03ec2a",
     "grade": false,
     "grade_id": "cell-6758c9a51eeb8506",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389c929-2caa-452a-82f7-2426a2d823df",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e72f5b82d21f2e6a8fbea3f97988ecf",
     "grade": true,
     "grade_id": "cell-b96d042aea36da35",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(gain_ratio(trial_df, 'b', 'label'), 0.6379740263133316)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fa772-9d53-4862-8c3f-21615186ce0d",
   "metadata": {},
   "source": [
    "## Part D)\n",
    "\n",
    "So far we have only handled categorical variables, we would like to also handle numerical variables.  What we will do is create a categorial variable out of our numeric variables by create a point $p$ and then each point is either $<=p$ or $>p$.  Once we create this point, we have a categorical feature of True, False values.  The trick here is how to compute the correct $p$.  The way we will do this is as follows:\n",
    "\n",
    "1.  What we do is for each value of the attribute, we split the dataset into all values less than or equal to that value and all values greater than that value.  \n",
    "2. We then compute the gain ratio as normal.  \n",
    "3. Take the $p$ which maximizes the gain ratio and use that in our fit.\n",
    "\n",
    "In this problem, define a `max_numeric_gain_ratio` function which computes the correct $p$.  Your function should return a tuple consisting of (max_value, number_to_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a867cb-b877-41ab-9417-b7151f346e23",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61fc7aef3719f893140283a03f4c6d40",
     "grade": false,
     "grade_id": "cell-bd7c5f57ddb07b19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def max_numeric_gain_ratio(df: pd.DataFrame, key: str, label_key: str):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d038ff-dc8a-4f46-9b3c-21425b7f0983",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b85159ae34f35b114eb2ea71d096dd",
     "grade": true,
     "grade_id": "cell-28bc9424031b48a3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = max_numeric_gain_ratio(trial_df, 'a','label')\n",
    "assert_almost_equal(res[0],  0.4459281986214854)\n",
    "assert res[1] == 3, f\"{res[1]} != 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89204e7d-f546-4ccc-8512-ba3118aa9d77",
   "metadata": {},
   "source": [
    "## Part E)\n",
    "\n",
    "Lets start by implementing the simple id3 algorithm which will give us a good sense of how to do the more complex algorithm.\n",
    "\n",
    "We will make a fake dataset of 10 observations with a label of true false for how well someone sleeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b663d-651a-4477-b1c1-3790b5f5a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_data = pd.DataFrame({\n",
    "    'day_type': ['long', 'long', 'short', 'medium', 'short', 'short', 'medium', 'long', 'short', 'short'],\n",
    "    'weekend': [True, False, False, False, False, False, True, True, True, False],\n",
    "    'good_night_before': [True, True, False, True, True, False, False, False, False, True],\n",
    "    'label': [True, False, False, False, True, False, True, False, True, False]\n",
    "})\n",
    "id3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e35dec-8670-44de-81c5-008182a89e87",
   "metadata": {},
   "source": [
    "Next we will define an `Id3Node` class which will be used to hold the data for our algorithm.  Each of these nodes will be the node in a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f296fd-989b-48b7-a8e2-07262da739c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional\n",
    "@dataclass\n",
    "class Id3Node:\n",
    "    key: str\n",
    "    children: Optional[Dict[str, 'Node']] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0c9ab-35ec-476a-8957-5141db28a5e5",
   "metadata": {},
   "source": [
    "Now we can implement the `train_id3` method.  This method should take a dataframe and return an `Id3Node` which represents the trained tree.  Please note that the `gain_ratio` is a bit unconventional to use as the splitting critera, but we are using it here as it will help us generalize into the c4.5 algorithm.\n",
    "\n",
    "*Hint*: Since we are here only implementing the ID3 algorithm, we do not need to worry about numeric columns.  Thus, we shouldn't yet need to use our `max_numeric_gain_ratio` function from before, but rather only the `gain_ratio` function.  \n",
    "\n",
    "It is quite likely (although not strictly required) that your algorithm be recursive in nature.  Like any recursive algorithm, play close attention to the base cases defined above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7037c2-6836-45bd-ab3a-61bfce495d6d",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7717c5fadb91f054799f6d3bf816fb55",
     "grade": false,
     "grade_id": "cell-89579c32d1cdc0d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_id3(df: pd.DataFrame) -> Id3Node:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed872f-a9c0-4b01-a079-8251e70845cc",
   "metadata": {},
   "source": [
    "Now we can create a `predict_id3` method which takes in a single row of a `DataFrame` (which is a `Series`) and a trained `Id3Node` (the root node) to make a prediction.\n",
    "\n",
    "The prediction should take the row and walk down the tree at each step choosing the proper child given the row information until it gets to a leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e50306-92a8-4dd2-8b79-625b10513853",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "102a316dfb5d8d689ed518e6ef3aec54",
     "grade": true,
     "grade_id": "cell-3b04a7162c97cc06",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_id3(row: pd.Series, node: Id3Node):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a5f77-25d8-4530-b891-def9522c629f",
   "metadata": {},
   "source": [
    "Now put it all together, fill in the `fit` and `predict` methods for the `Id3Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d46ea4-65f3-40b1-97b0-3f9f4ed4ae57",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ce3278f4062a29dd4d5006e71d6fad5",
     "grade": true,
     "grade_id": "cell-ae496f77f77055bb",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelNotTrainedError(ValueError):\n",
    "    \"\"\"model is not trained yet\"\"\"\n",
    "        \n",
    "class Id3Model:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, df):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def predict(self, df):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1d083-26eb-43a1-8419-ddd0665e3963",
   "metadata": {},
   "source": [
    "## Part E) (BONUS)\n",
    "\n",
    "This is a bonus part to the problem.  It is not trivial to implement, but I encourage you to try!  Partial or correct solutions to this part will be worth some extra credit.\n",
    "\n",
    "We have already implemented the ID3 algorithm, now you can use the functions before to implement the same for the numeric types.\n",
    "\n",
    "Now we can put it all together, implement a training algorithm which produces a trained tree. To help you, we will define a class `Node` as well as a visualize function to produce an image of the node, you can choose to use your own data structure if you so wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b0d0f-db51-4be1-a706-9d264b5beb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "@dataclass\n",
    "class Node:\n",
    "    key: str\n",
    "    numeric: bool\n",
    "    pivot: float\n",
    "    children: Dict[str, 'Node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2704a-59d6-4725-893e-8727793e9c24",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "302d32116c9eee298aab3500c2fefb0a",
     "grade": true,
     "grade_id": "cell-287faaaf5ff85def",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d5967-4e84-499d-a430-2129c4850924",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f575b28c8287cc9723cdc26a036ad7c2",
     "grade": false,
     "grade_id": "cell-b1a53d934e0ea394",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "## Part f)\n",
    "\n",
    "Now use this algorithm to fit the wine dataset below.  Give an overview of your results and an explanation of your findings.  If you did not do the bonus problem in part e), you may use the class below or the `scikit-learn` model directly.  The class is a very simple wrapper to conform to the dataframe format we have been using.\n",
    "\n",
    "\n",
    "Some questions to consider:\n",
    "\n",
    "1. Do your results make sense?\n",
    "\n",
    "**Note**: It may take some time to train your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8068a9-c31b-4469-be34-16f2c2d7f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "class DecisionTreeModel(DecisionTreeClassifier):\n",
    "    \n",
    "    def fit(self, df):\n",
    "        if 'label' not in df:\n",
    "            raise ValueError(\"Label is not in df\")\n",
    "        X = df.drop('label', axis=1)\n",
    "        self.columns_ = X.columns.tolist()        \n",
    "        super().fit(X.values, df['label'].values)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, df):\n",
    "        X = df[self.columns_].values if isinstance(df, pd.DataFrame) else df\n",
    "        return super().predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0df07-d35b-45d7-bf85-0ef79e731ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "dataset = load_wine()\n",
    "df = pd.DataFrame(dataset['data'], columns=dataset['feature_names'])\n",
    "df['label'] = dataset['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac06a4d-45ed-4a4f-a491-35175648997b",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "In this problem, we will implement the perceptron algorithm as defined in the book, below is the skeleton class we will want to implement.\n",
    "\n",
    "Your alogorithm should take as a hyperparametr `max_iters` which is the number of times it will iterate through the training set entirely.\n",
    "\n",
    "Please include a `get_params` method which returns a `PerceptronParams` class with the current parameters of the model.  Its your choice how you store these, but this method must return this object type as it will be used to validate your results.\n",
    "\n",
    "For consistency with the results, please initialize all weights and biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a6915-41e7-4c9f-87da-587ec96b05a1",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b98356b28249c3f721070e98b8f8eb6",
     "grade": true,
     "grade_id": "cell-7cd0ee9cbbaed97b",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "@dataclass\n",
    "class PerceptronParams:\n",
    "    weights: List[float]\n",
    "    bias: float\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, max_iters=20):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_params(self) -> PerceptronParams:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    def fit(self, df, callback=None):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, df):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed7c36-5381-4846-aa9e-40fa53ffe172",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Now lets explore linear separability with some fake datasets.\n",
    "\n",
    "First we will import some data which is linearly separable.  This is already done in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2a9b3-ac08-4e84-9f01-9841815f025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "linear_separable_df = pd.read_csv('linearly_separable.csv')\n",
    "linear_separable_df.plot.scatter(x=0, y=1, c='label', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75daeb5-f47b-4bd7-8a46-511bd28b8028",
   "metadata": {},
   "source": [
    "Now train a perceptron and plot the best fit line on top of the scatter plot from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258e775-2ae4-4c2e-b484-0b5700d0e079",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf5ab3aac4e653f1bf6c26a93d62f741",
     "grade": true,
     "grade_id": "cell-1f907e71b21bb412",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385e368-4a31-469c-b62a-bec480e9a1e8",
   "metadata": {},
   "source": [
    "Now lets examine how the line evolves as the model is trained.  Make a plot showing how the line changes per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca6e80-c703-4838-bca7-13453bc64fae",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3aa5098659adcc91764b13f1a607d47b",
     "grade": true,
     "grade_id": "cell-572d2d980ae09171",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db16bf-034e-43d8-a69c-d498b2331522",
   "metadata": {},
   "source": [
    "## Part B (Bonus - extra credit)\n",
    "\n",
    "For extra credit, implement averaging in the perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d019054-acca-427a-9982-944ffd4b6193",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c434d5b6617e0fe9a80a3ca68dee707",
     "grade": true,
     "grade_id": "cell-a17fa9016ea8266e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AveragePerceptron(Perceptron):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6db3a-1983-4129-95b9-67f609c342d0",
   "metadata": {},
   "source": [
    "Now make the same plot as in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6ebf4-7177-48d6-9b51-d5005a17dc7e",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0b187f193dc01f48bb08f566d080a72",
     "grade": true,
     "grade_id": "cell-8651ac46df11daed",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7f79a-add7-4c05-9ff6-472f81beea59",
   "metadata": {},
   "source": [
    "## Part c\n",
    "\n",
    "Analyze the stability of the weights as a function of iteration, If you did part b, please include it in your analysis.  Some points to consider\n",
    "\n",
    "- How stable were they over time?\n",
    "- How many iterations were appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef004a9-4a54-4c04-afa1-d2dcdb371333",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0d99b6519acb800302e028122299d72",
     "grade": true,
     "grade_id": "cell-940423dbc76c5042",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a264c-1230-4b5c-a227-eb8fe10db31d",
   "metadata": {},
   "source": [
    "# Problem 3 conceptual\n",
    "\n",
    "For this problem, write each answer in the cell immediately following the question which will be marked.\n",
    "\n",
    "## Part a)\n",
    "\n",
    "The algorithm we have used to train the decision tree is a greedy algorithm.  Explain why we use a greedy algorithm and what consequences this has on the resulting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55ec5a-5728-41e6-bde5-29f93e3de7be",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f26c516a036bcfb63f795625786b7ea0",
     "grade": true,
     "grade_id": "cell-caf5149447628dd7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee7513-985a-4dee-82bd-f447830ec4b4",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "\n",
    "In our perceptron algorithm, *IN YOUR OWN WORDS*, why is it important to shuffle the datasets?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89bec1-a9ac-48ec-ab80-6fe5a808f081",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4839332aeab51e9b658b0455db4a232c",
     "grade": true,
     "grade_id": "cell-b11934c7dab18f43",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909ceb1-cbc6-4cb1-b91e-a17077838edd",
   "metadata": {},
   "source": [
    "## Part c)\n",
    "\n",
    "Is a decision tree guaranteed to find a globally optimal solution?  If not, what are the barriers to creating an algorithm to find the globally optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cb103-85e3-4b12-a3bf-2137123f9fb9",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a3414c4a781fa090b0eae371e88b17e",
     "grade": true,
     "grade_id": "cell-b6a56fee4b473efe",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb4238-2c5f-4b41-82f6-806b857e72a1",
   "metadata": {},
   "source": [
    "# Problem 4 - Data Problem\n",
    "\n",
    "Problem 4 is the real world simulation problem.  Here I will simply give you a dataset and a problem, your goal is to solve the problem and list all of your assumptions as well as your results.  This is meant to simulate many of the types of problems you may see in the future on an interview.\n",
    "\n",
    "You will be evaluated on how well you use the techniques we have learned so far in the course, you will not need to have the best model, you will be evaluated more on how you think and explain your solution.\n",
    "\n",
    "Here we are going to use the very common dataset, california housing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1043cad-4399-4dc6-9d1c-aac3925fab21",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a02294705690c566794120b7055516af",
     "grade": false,
     "grade_id": "cell-4a6bd002c206bce5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "## Part a)\n",
    "\n",
    "First of all do some exploratory data analysis and report your findings.  The following function will get the data for you, please take it from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045abd6b-1910-487d-81fa-f38ae3ac2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "blob = fetch_california_housing()\n",
    "df = pd.DataFrame(blob['data'], columns=blob['feature_names'])\n",
    "df[blob['target_names'][0]] = blob['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f50a3-9293-4a89-a6d4-2fc842c8d6f4",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "\n",
    "Before modeling, its often good to start with a baseline model, something simple which will give us some indication if the model we are building is actually learning something.  Lets start by building a model which predicts that the median housing price of a block is the median of the entire dataset.  Please compute the mean squared error of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7590d-6768-4e88-8c13-6b722504bcdc",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1be37974247a5fe64146ed9de374afe",
     "grade": true,
     "grade_id": "cell-6dbc46a56ce14db0",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fe09d-2faa-4f9d-bbf0-da420350d018",
   "metadata": {},
   "source": [
    "## Part c)\n",
    "\n",
    "In this problem we are going to use a linear regression to explore this dataset.  We will learn more about scikit-learn in the future, here you will be provided with an object to fit a dataframe to a linear model.  You are welcome to use the `scikit-learn` object directly if you so choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884f195-b0bf-42f3-9b4c-cc25bce85853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class LinearModel:\n",
    "    def __init__(self, fit_intercept: bool = True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.target_variable: Optional[str] = None\n",
    "        self.columns: Optional[List[str]] = None\n",
    "        self.model: Optional[LinearRegression] = None\n",
    "        \n",
    "    def _check_fit(self):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"model is not yet fit\")\n",
    "        \n",
    "    def fit(self, df: pd.DataFrame, target_variable: str) -> 'LinearModel':\n",
    "        \"\"\"fit a dataframe and return the coefficients and intercept\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df: pd.DataFrame\n",
    "            Input dataframe for fitting, should contain target variable\n",
    "        target_variable: str\n",
    "            Target variable for fitting, must be in the dataframe\n",
    "        \"\"\"\n",
    "        self.target_variable = target_variable\n",
    "        X = df.drop(target_variable, axis=1)\n",
    "        y = df[target_variable].values\n",
    "        self.columns = X.columns\n",
    "        self.model = LinearRegression(fit_intercept=self.fit_intercept)\n",
    "        self.model.fit(X.values, y)\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def coef(self):\n",
    "        self._check_fit()\n",
    "        return dict(zip(self.columns, self.model.coef_))\n",
    "    \n",
    "    @property\n",
    "    def intercept(self) -> float:\n",
    "        self._check_fit()\n",
    "        return self.model.intercept_\n",
    "\n",
    "    \n",
    "    def predict(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted model\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df: pd.DataFrame\n",
    "            Input dataframe for prediction\n",
    "        \"\"\"\n",
    "        self._check_fit()\n",
    "        X = df[self.columns].values\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2beefcc-702f-4cee-a45f-b508f5e8c774",
   "metadata": {},
   "source": [
    "Start off by fitting the linear regression directly to the dataset and then interpret your results.  Remove the Latitude and Longitude information for now (more on this in the next part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd542e69-620d-4539-ad1e-ab83e6717e53",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d50fca57e2df155eafe3b73d3777f7c5",
     "grade": true,
     "grade_id": "cell-71f2bc4b66decbf2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b004565-8f0c-42d2-903b-714a6e80ce63",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84a7942345f03143c2e74c8a3923a87f",
     "grade": false,
     "grade_id": "cell-e4323c31769fda89",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "## Part d)\n",
    "\n",
    "Latitude and Longitude are different sorts of features than the rest of the features in this dataset, please explain why.\n",
    "\n",
    "**Hint**: Try making a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a86a4-b8d5-4987-b3c1-198f36ca1073",
   "metadata": {},
   "source": [
    "## Part e) (Bonus)\n",
    "\n",
    "Now we are going to use the latitude and longitude to generate some new features.  Often in an ML problem, bringing more is how we can best improve our predictive accuracy.\n",
    "\n",
    "Instead of using directly, lets create a feature which is minimum distance from a \"major\" city, defined as having greater than .5 million people.\n",
    "\n",
    "I have looked up the following wikipedia:\n",
    "\n",
    "| City | Latitude | Longitude |\n",
    "| --- | ---| ---|\n",
    "|Los Angeles| 34.03| -118.15|\n",
    "|San Diego|32.4254| -117.0945|\n",
    "|San Francisco|37.4639| -122.2459|\n",
    "|San Jose |37.2010| -121.5326|\n",
    "|Sacramento|38.3454| -121.2940|\n",
    "\n",
    "You are welcome to use any distance metric you like, however, one good one would be from the geopy library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161a1c9-b677-4a55-928e-4ea778c5517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_longs = [\n",
    "    (34.04, -118.15),\n",
    "    (32.4254, -117.0945),\n",
    "    (37.4639, -122.2459),\n",
    "    (37.2010, -121.5326),\n",
    "    (38.3454, -121.2940)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1182509-5898-4ff2-85d0-385507c96084",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3967dff95fd27da77af8378cedb7468a",
     "grade": true,
     "grade_id": "cell-bd9ec73649132f14",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30214d8-a103-45ae-ae7b-2791f0ba62e9",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11992a1fe14048b0c13cf0af4cafbe66",
     "grade": false,
     "grade_id": "cell-6a0aa83581a8cea9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "## Part f)\n",
    "\n",
    "Now please create the best linear model that you can, produce a explanation of the decision you made and why this is a \"good\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d6584-2138-45c9-b88e-f55c05b806d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
