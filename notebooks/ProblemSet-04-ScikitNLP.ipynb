{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6106db4f",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c530ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18db0f2",
   "metadata": {},
   "source": [
    "# PS4 Project\n",
    "\n",
    "In this project, we are going to continue learning more about scikit-learn and modeling by building another complete model. We also might learn a little NLP along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "bunch = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08893339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bunch['DESCR'])\n",
    "\n",
    "#for i in range(len(bunch.data)):\n",
    "    #print(i, \"example\", bunch.target[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425425b5-2d93-4570-b8f1-3e6b9dcfdd2c",
   "metadata": {},
   "source": [
    "## Part a)\n",
    "\n",
    "For each of the following words\n",
    "\n",
    "- the\n",
    "- subject\n",
    "- computer\n",
    "- player\n",
    "- democrat\n",
    "\n",
    "please compute the overall percentage of the documents the word appears in a document as well as for each class the percentage of documents the word appears in.  Please ignore case in your calculation.  I have provided the words in a list in the cell below.\n",
    "\n",
    "Please provide your answer in the following format\n",
    "\n",
    "```\n",
    "ans = {\n",
    "   <word>: {\n",
    "       total_perc: <perc>, \n",
    "       subject_percs: {\n",
    "           <subject>: <perc>\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "If a word does not appear in the subject, do not include it in the `subject_percs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bed997",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['the', 'subject', 'computer', 'player', 'democrat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609e5d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67fb980fc96a92eb64a55eb5e6c964d5",
     "grade": false,
     "grade_id": "cell-7532f8ec92d39fc6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def def_value():\n",
    "    return 0\n",
    "\n",
    "def compute_percentages(bunch):\n",
    "    \n",
    "    d = defaultdict(def_value)\n",
    "    \n",
    "   # YOUR CODE HERE\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab799e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "def assert_almost_equal(a, b):\n",
    "    assert abs(a - b) < 1e-5, f\"a={a:.5f}, b={b:.5f} are not euql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fdbf4d",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a558219860d0331a9f65a167157c9494",
     "grade": true,
     "grade_id": "cell-674e347558499603",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ans = compute_percentages(bunch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e51b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "092286c4bd61561406415ce95a567f58",
     "grade": false,
     "grade_id": "cell-278456d4bf8a121d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Part b)\n",
    "\n",
    "Now interpret your results with a plot which shows for each word the relative percentages for each subject.  To make the plots a bit simpler, lets just consider 4 subjects:\n",
    "\n",
    "- rec.sport.baseball\n",
    "- talk.politics.misc\n",
    "- comp.graphics\n",
    "- talk.rec.motorcycles\n",
    "\n",
    "these are provided as a list in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2715e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['rec.sport.baseball', 'talk.politics.misc', 'comp.graphics', 'rec.motorcycles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "d = compute_percentages(bunch)\n",
    "\n",
    "# YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5514b",
   "metadata": {},
   "source": [
    "## Part c)\n",
    "\n",
    "Build a classifier to try to identifier whether the text belongs to one of the `comp` news groups.  This is a  binary classification problem.\n",
    "\n",
    "The features will be the number of occurances of each word in the problem.  You are recommended to use Scikit-learn logistic regression for your implementation.\n",
    "\n",
    "As hyperparameters, play with the maximum and minimum document frequency for words. (a gridsearch could be a good thing to use to find the optimal hyperparameters!)\n",
    "\n",
    "NOTE: max_df and min_df play with what percentage of documents it will appear in  and whether it is significant or helpful, e.g. \n",
    "```\n",
    "    'max_df': [100,500,1000,2000], \n",
    "    'min_df': [0,1,2,3,5,10,100]\n",
    "```\n",
    "\n",
    "Your answer should create a fitted `Estimator` called `classifier_model` which will be used in the testing,\n",
    "\n",
    "The Scikit estimators you need to import are in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b60d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65ec8e",
   "metadata": {},
   "source": [
    "The datasets will be prepared in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessingStep(bunch):\n",
    "\n",
    "    #data clean up (remove extraneous data)\n",
    "\n",
    "    #remove extraneous data that will cause overfitting\n",
    "    bunch = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "    info = {}\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    #create a data frame with the data and the label\n",
    "    info = {'data': data, 'labels': label}\n",
    "    df = pd.DataFrame(info)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f92b",
   "metadata": {},
   "source": [
    "## THOUGHT PROCESS: \n",
    "\n",
    "    Use this cell to explain the thought process behind your implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03259f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement classifier_model\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# YOUR CODE HERE\n",
    "# preprocessing, \n",
    "# pipeline with feature transformation \n",
    "# train test splits\n",
    "# model fitting, \n",
    "# accuracy metrics and reports\n",
    "# inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea968191",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81f98ec125240ebcf2a4c40e3919cf21",
     "grade": true,
     "grade_id": "cell-14b98ec39b2ebaf6",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn import base\n",
    "\n",
    "assert isinstance(classifier_model, base.BaseEstimator)\n",
    "# lets make sure it runs with no errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
