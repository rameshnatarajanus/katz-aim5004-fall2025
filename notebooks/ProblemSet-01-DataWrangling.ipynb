{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afbadd2-ed71-4f4f-aa95-02338be0a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Sarale Goldberger\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c80f6a-1909-4044-bec2-cfb5f50a3f61",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Instructions\n",
    "\n",
    "1. Make sure you have filled out your \"NAME\" and \"COLLABORATORS\" (if any) in the previous cell.\n",
    "\n",
    "2. You should complete all code/markdown cells that state \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\". \n",
    "   \n",
    "3. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "4. Partial credit can be obtained if your solution approach is clear and the documented within comments in the implementation.\n",
    "\n",
    "5. You should follow good coding practices. Your code should use type hints, be robust against invalid inputs, and you should also write a few test cases to check for correctness particularly including edge cases.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac0a45-dcba-4342-92cc-d6157f9c4ad8",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Write a python function which computes third power of a number if the number is odd, and the square of the number if the number is even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8038a5-6603-4656-b66a-493dfc69ffa6",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab5cc25f191920f285f301e32d8cacb6",
     "grade": false,
     "grade_id": "cell-14b79c9cb73bbf40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the function takes in an int x and returns an int\n",
    "def parity_power(x: int) -> int:\n",
    "    if x % 2 == 0:\n",
    "        return x**2\n",
    "    return x**3\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21b5e3f-47b2-4024-963d-703812caaeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function works!\n"
     ]
    }
   ],
   "source": [
    "# provide test cases\n",
    "assert parity_power(1) == 1\n",
    "assert parity_power(2) == 4\n",
    "assert parity_power(3) == 27\n",
    "assert parity_power(24) == 24**2\n",
    "assert parity_power(377) == 377**3\n",
    "print(\"Your function works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27312f8f-0127-4ddd-b03a-16b3ec4a996d",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "An important part of this course is to complete an ML based project over the course of the semester.  We are going to start right now!\n",
    "\n",
    "Read the description of the project uploaded on canvas and write down 2 potential ideas for your project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ed13f-bbaa-4c06-804f-51d03ceb4047",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94c245d935d153aae4844ae075062962",
     "grade": true,
     "grade_id": "cell-e119bc622f6ff41b",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "I submitted my ideas in the 'Term Project Ideas' assignment in Canvas. My idea is to use my NLP research with Professor Waxman. I will be taking audio recordings of classes which have a mix of English, Hebrew, Yiddish, Arameic, and Yeshivish slang words, running them through WhisperAI to obtain preliminary transcriptions, and then using prompt strategies to train ChatGPT to fix the mistakes in the non-English words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e263c7-fb99-42f6-aa10-337f286cb9a7",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "This problem will test some of your programming skills and data wrangling ability.  \n",
    "\n",
    "We will start with a dataset from 'https://github.com/JeffSackmann/tennis_atp' which covers information on Tennis matches from the past few decades.  \n",
    "\n",
    "This dataset is provided by Jeff Sackman.\n",
    "\n",
    "Write a function *download_data_by_year* which takes the year as an input and returns a pandas dataframe with the data from the file of the form `atp_matches_{year}.csv`.  Implement a cache so that we do not download the data if it is already in the cache. \n",
    "\n",
    "**Hint**: The url you need to use to access the files in github is https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_{year}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4c4314-0000-4ea7-9ebc-0156b6a3ad5a",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4768215f068a6e9130081f9cd05e620",
     "grade": false,
     "grade_id": "cell-9954e13bab216e43",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# cache for the df's that have already been downloaded\n",
    "cache = {}\n",
    "\n",
    "def download_data_by_year(year: int) -> pd.DataFrame:\n",
    "    # Check if the input year has already been downloaded\n",
    "    if year in cache:\n",
    "        return cache[year]\n",
    "\n",
    "    url = f\"https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_{year}.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        cache[year] = df\n",
    "        return df\n",
    "        \n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error parsing data\")\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4dd82d0-bda4-4e8d-8cff-7edd708d82f9",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6f57484d4832b5dce9c1a611f022b68",
     "grade": true,
     "grade_id": "cell-bcd973ba4d369a21",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = download_data_by_year(2017)\n",
    "assert df.shape == (2911, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "668403c2-560b-4042-926b-310625b9064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and target Features\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2911 entries, 0 to 2910\n",
      "Data columns (total 49 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tourney_id          2911 non-null   object \n",
      " 1   tourney_name        2911 non-null   object \n",
      " 2   surface             2911 non-null   object \n",
      " 3   draw_size           2911 non-null   int64  \n",
      " 4   tourney_level       2911 non-null   object \n",
      " 5   tourney_date        2911 non-null   int64  \n",
      " 6   match_num           2911 non-null   int64  \n",
      " 7   winner_id           2911 non-null   int64  \n",
      " 8   winner_seed         1238 non-null   float64\n",
      " 9   winner_entry        403 non-null    object \n",
      " 10  winner_name         2911 non-null   object \n",
      " 11  winner_hand         2910 non-null   object \n",
      " 12  winner_ht           2876 non-null   float64\n",
      " 13  winner_ioc          2911 non-null   object \n",
      " 14  winner_age          2911 non-null   float64\n",
      " 15  loser_id            2911 non-null   int64  \n",
      " 16  loser_seed          716 non-null    float64\n",
      " 17  loser_entry         630 non-null    object \n",
      " 18  loser_name          2911 non-null   object \n",
      " 19  loser_hand          2906 non-null   object \n",
      " 20  loser_ht            2836 non-null   float64\n",
      " 21  loser_ioc           2911 non-null   object \n",
      " 22  loser_age           2911 non-null   float64\n",
      " 23  score               2911 non-null   object \n",
      " 24  best_of             2911 non-null   int64  \n",
      " 25  round               2911 non-null   object \n",
      " 26  minutes             2837 non-null   float64\n",
      " 27  w_ace               2870 non-null   float64\n",
      " 28  w_df                2870 non-null   float64\n",
      " 29  w_svpt              2870 non-null   float64\n",
      " 30  w_1stIn             2870 non-null   float64\n",
      " 31  w_1stWon            2870 non-null   float64\n",
      " 32  w_2ndWon            2870 non-null   float64\n",
      " 33  w_SvGms             2870 non-null   float64\n",
      " 34  w_bpSaved           2870 non-null   float64\n",
      " 35  w_bpFaced           2870 non-null   float64\n",
      " 36  l_ace               2870 non-null   float64\n",
      " 37  l_df                2870 non-null   float64\n",
      " 38  l_svpt              2870 non-null   float64\n",
      " 39  l_1stIn             2870 non-null   float64\n",
      " 40  l_1stWon            2870 non-null   float64\n",
      " 41  l_2ndWon            2870 non-null   float64\n",
      " 42  l_SvGms             2870 non-null   float64\n",
      " 43  l_bpSaved           2870 non-null   float64\n",
      " 44  l_bpFaced           2870 non-null   float64\n",
      " 45  winner_rank         2894 non-null   float64\n",
      " 46  winner_rank_points  2894 non-null   float64\n",
      " 47  loser_rank          2873 non-null   float64\n",
      " 48  loser_rank_points   2873 non-null   float64\n",
      "dtypes: float64(29), int64(6), object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Print part of the dataset\n",
    "print(\"Input and target Features\")\n",
    "# display(pd.concat([df.data, df.target], axis=1).head())\n",
    "df.info()\n",
    "# df.filter([\"surface\", \"draw_size\", \"tourney_level\", \"minutes\"]).sort_values(by=['draw_size'])\n",
    "# df.groupby([\"tourney_level\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f3d14-c5a7-4476-8bf9-b7f9ac6a331f",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "Download the data for years 2000-2020 (inclusive).  Compute the average number of matches played per year on each surface for each month. \n",
    "\n",
    "Return your solution as a dictionary where the key is the (surface, month) pair as a tuple and the value is the average.\n",
    "\n",
    "**Hint**: You may have a case where no matches were played on a given surface in a month.  This should factor into your calculation as a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c95e4f5-e6db-4009-986b-c6eb7acef624",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46b84cd6fba9d6ec9c4f1a53054236cb",
     "grade": false,
     "grade_id": "cell-be49d8719f86849f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>...</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>1</td>\n",
       "      <td>103163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>2</td>\n",
       "      <td>102607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>3</td>\n",
       "      <td>103252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>4</td>\n",
       "      <td>103507</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>5</td>\n",
       "      <td>102103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2020-7485</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20201019</td>\n",
       "      <td>125</td>\n",
       "      <td>105554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2020-7485</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20201019</td>\n",
       "      <td>126</td>\n",
       "      <td>200267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2020-7485</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20201019</td>\n",
       "      <td>128</td>\n",
       "      <td>126203</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2020-7485</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20201019</td>\n",
       "      <td>129</td>\n",
       "      <td>144750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>2020-7485</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20201019</td>\n",
       "      <td>130</td>\n",
       "      <td>200005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63194 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "0      2000-301     Auckland    Hard         32             A      20000110   \n",
       "1      2000-301     Auckland    Hard         32             A      20000110   \n",
       "2      2000-301     Auckland    Hard         32             A      20000110   \n",
       "3      2000-301     Auckland    Hard         32             A      20000110   \n",
       "4      2000-301     Auckland    Hard         32             A      20000110   \n",
       "...         ...          ...     ...        ...           ...           ...   \n",
       "1457  2020-7485      Antwerp    Hard         32             A      20201019   \n",
       "1458  2020-7485      Antwerp    Hard         32             A      20201019   \n",
       "1459  2020-7485      Antwerp    Hard         32             A      20201019   \n",
       "1460  2020-7485      Antwerp    Hard         32             A      20201019   \n",
       "1461  2020-7485      Antwerp    Hard         32             A      20201019   \n",
       "\n",
       "      match_num  winner_id  winner_seed winner_entry  ... l_2ndWon l_SvGms  \\\n",
       "0             1     103163          1.0          NaN  ...     29.0    17.0   \n",
       "1             2     102607          NaN            Q  ...     18.0    12.0   \n",
       "2             3     103252          NaN          NaN  ...      7.0     8.0   \n",
       "3             4     103507          7.0          NaN  ...     14.0    10.0   \n",
       "4             5     102103          NaN            Q  ...     18.0    12.0   \n",
       "...         ...        ...          ...          ...  ...      ...     ...   \n",
       "1457        125     105554          NaN          NaN  ...     14.0    13.0   \n",
       "1458        126     200267          NaN           WC  ...     10.0    12.0   \n",
       "1459        128     126203          7.0          NaN  ...      5.0     9.0   \n",
       "1460        129     144750          NaN            Q  ...      5.0    10.0   \n",
       "1461        130     200005          NaN          NaN  ...      7.0     9.0   \n",
       "\n",
       "      l_bpSaved l_bpFaced  winner_rank  winner_rank_points  loser_rank  \\\n",
       "0           4.0       7.0         11.0              1612.0        63.0   \n",
       "1           3.0       6.0        211.0               157.0        49.0   \n",
       "2           7.0      11.0         48.0               726.0        59.0   \n",
       "3           6.0       8.0         45.0               768.0        61.0   \n",
       "4           5.0       9.0        167.0               219.0        34.0   \n",
       "...         ...       ...          ...                 ...         ...   \n",
       "1457        3.0       7.0         35.0              1384.0        79.0   \n",
       "1458        4.0       9.0        528.0                58.0        45.0   \n",
       "1459        3.0       5.0         28.0              1670.0        33.0   \n",
       "1460        7.0      11.0         90.0               748.0        74.0   \n",
       "1461        2.0       4.0         38.0              1306.0       172.0   \n",
       "\n",
       "     loser_rank_points  year month  \n",
       "0                595.0  2000     1  \n",
       "1                723.0  2000     1  \n",
       "2                649.0  2000     1  \n",
       "3                616.0  2000     1  \n",
       "4                873.0  2000     1  \n",
       "...                ...   ...   ...  \n",
       "1457             802.0  2020    10  \n",
       "1458            1165.0  2020    10  \n",
       "1459            1402.0  2020    10  \n",
       "1460             838.0  2020    10  \n",
       "1461             353.0  2020    10  \n",
       "\n",
       "[63194 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the data for years 2000-2020 incl.\n",
    "# initialize a df with the data from 2000, and concatenate the rest of the years\n",
    "# add a year and month column, assuming 'tourney_date' column contains integers in the format YYYYMM\n",
    "df = download_data_by_year(2000)      \n",
    "df['year'] = 2000   \n",
    "df['month'] = (df['tourney_date'] % 10000) // 100\n",
    "\n",
    "for year in range(2001, 2021):\n",
    "    # download the data\n",
    "    temp = download_data_by_year(year)\n",
    "\n",
    "    ## To check if there is a row with 5 for month and Carpet for surface.\n",
    "    #print(year, ((df['month'] == 5) & (df['surface'] == 'Carpet')).any())\n",
    "    \n",
    "    # add year and month cols\n",
    "    temp['year'] = year\n",
    "    temp['month'] = (temp['tourney_date'] % 10000) // 100 # convert to pd.datetime and call month function on it \n",
    "    # concatenate the df to our larger df\n",
    "    df = pd.concat([df, temp])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "630cd5bb-a218-48c5-8135-30e1723568f2",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46b84cd6fba9d6ec9c4f1a53054236cb",
     "grade": false,
     "grade_id": "cell-be49d8719f86849f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_statistics(df):\n",
    "    return df.groupby(['year', 'month', 'surface']).agg('mean')\n",
    "    \n",
    "    # compute the average number of matches played per year on each surface for each month\n",
    "    # df_grouped = df.groupby(['year', 'month', 'surface']).size().reset_index(name='matches')\n",
    "    # df_grouped_avg = df_grouped.groupby(['surface', 'month']).mean().round().astype(int).reset_index().fillna(0)\n",
    "    # print(\"df_grouped_avg\\n\", df_grouped_avg)\n",
    "    ##print(\"Dimensions:\", df_grouped_avg.shape)\n",
    "\n",
    "\n",
    "    # # create a dictionary where the key is the match, month pair as a tuple \n",
    "    # # and the value is the average\n",
    "    # # there will be 12 * 4 keys for the 12 months * 4 surface types per month\n",
    "    # dict = {}\n",
    "    # months = [i for i in range(1,13)]\n",
    "    # surfaces = ['Carpet', 'Clay', 'Grass', 'Hard']\n",
    "    # i = 0\n",
    "    # for ind in range(len(df_grouped_avg)):\n",
    "    #     mo = i%12 + 1  # expected month\n",
    "    #     mo_df = df_grouped_avg['month'].iloc[ind]\n",
    "    #     # if there are missing months add them in with data as 0\n",
    "    #     if mo < mo_df:\n",
    "    #         for j in range(mo, mo_df):\n",
    "    #             dict[(df_grouped_avg['surface'].iloc[ind], j)] = 0\n",
    "    #         i += mo_df - mo\n",
    "    #     elif mo > mo_df:\n",
    "    #         for j in range(mo, 13):\n",
    "    #             dict[(df_grouped_avg['surface'].iloc[ind-1], j)] = 0\n",
    "    #             i += 1\n",
    "    #     # add the key-data pair of the current month and surface\n",
    "    #     data = df_grouped_avg['matches'].iloc[ind]\n",
    "    #     key = (df_grouped_avg['surface'].iloc[ind], mo_df)\n",
    "    #     dict[key] = data\n",
    "    #     # increment month tracker\n",
    "    #     i+=1\n",
    "    # ##print(f\"All months accounted for {i==len(months)*len(surfaces)}: i {i}, exp {len(months)*len(surfaces)}\")\n",
    "    # return dict\n",
    "\n",
    "    # raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "272b73bc-4fb1-4e55-ab95-f2e04d8d578e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1874\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1874\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/ops.py:877\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 877\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:2380\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2380\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2381\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2382\u001b[0m     )\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/series.py:6225\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6217\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6223\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6224\u001b[0m ):\n\u001b[0;32m-> 6225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/series.py:6133\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6132\u001b[0m     )\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/nanops.py:1693\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string '2000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3012000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3382000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-3392000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-4512000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-5802000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-8912000-D0662000-D0662000-D0742000-D0742000-D0742000-D074' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_allclose\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m assert_allclose(res[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCarpet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)], \u001b[38;5;241m27\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m, in \u001b[0;36mget_statistics\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_statistics\u001b[39m(df):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msurface\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/generic.py:1445\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1442\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m   1444\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 1445\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/apply.py:172\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/apply.py:586\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/apply.py:669\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[0;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, func)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:2378\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2372\u001b[0m         grouped_mean,\n\u001b[1;32m   2373\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2374\u001b[0m         engine_kwargs,\n\u001b[1;32m   2375\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2376\u001b[0m     )\n\u001b[1;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1929\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1931\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/internals/managers.py:1428\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1428\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/internals/blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1926\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1926\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1878\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m   1881\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "res = get_statistics(df)\n",
    "assert_allclose(res[('Carpet', 1)], 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf15ec-000f-448a-82c8-da1e4e1f8db5",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2346de55eb8baa31e60af8b854d5f573",
     "grade": false,
     "grade_id": "cell-be2dd85a6878fd5d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Problem 5\n",
    "\n",
    "Determine the BEST 5 players of all time.  There is not a definative answer here, this is your chance to show your creativity.  Please also explain how you arrived at your rankings.  You are free to use web resources to support your answer, but you MUST cite them as you use them.\n",
    "\n",
    "You should answer questions like:\n",
    "\n",
    "1. How did you define BEST?\n",
    "2. Where do you believe your analysis is flawed?\n",
    "3. What could you do to improve your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a890c5-7413-4dbc-b234-347ba1d70e49",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2346de55eb8baa31e60af8b854d5f573",
     "grade": false,
     "grade_id": "cell-be2dd85a6878fd5d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### My Step 1: Determine Rank of tourney_level\n",
    "According to Bing and Professor Natarajan, it is a widely known tennis fact that:\n",
    "a. Higher drawsize tournaments (e.g., Grand Slams) involve more players and rounds. These tournaments attract top-ranked players, making the competition fierce.\n",
    "b Lower drawsize tournaments (e.g., smaller ATP or WTA events) have fewer players, and the overall field is less competitive.\n",
    "\n",
    "I know the rank for draw_size (i.e., higher draw size = higher rank), but I don't have information for how to rank tourney_level. Therefore, I rank tourney level according to its correlation with draw size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72983835-c4d0-4a98-b520-aaaf493183d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine rank of tourney_level by finding the correlation between tourney_level and draw_size\n",
    "# Filter the df for those two columns, and find the median draw_size for each tourney_level\n",
    "df_filtered = df.filter(['draw_size', 'tourney_level']).sort_values(by=['tourney_level'])                                                 # filter the df\n",
    "df_draw_size_median = df_filtered.groupby(['tourney_level']).median().astype(int).sort_values(by=['draw_size'], ascending=False).reset_index()   # find median draw size per tourney level\n",
    "display(df_draw_size_median)\n",
    "\n",
    "# Use the rankings obtained above to add a facotred tourney_level column to a filtered df\n",
    "df_wtd = df.filter([\"winner_id\", \"winner_name\", \"loser_id\", \"loser_name\", \"draw_size\", \"tourney_level\"]).fillna(0)\n",
    "\n",
    "# Factorize the 'tourney_level' column\n",
    "factorized_values, unique_levels = pd.factorize(df_wtd['tourney_level'])\n",
    "\n",
    "# Create a dictionary mapping original levels to specific values\n",
    "mapping = {\n",
    "    'G': 2,\n",
    "    'M': 1.8,\n",
    "    'A': 1.6,\n",
    "    'F': 1.2,\n",
    "    'D': 1\n",
    "}\n",
    "\n",
    "# Map factorized values to specific values using the mapping dictionary\n",
    "df_wtd['tourney_level_factor'] = [mapping[unique_levels[i]] for i in factorized_values]\n",
    "display(df_wtd.sort_values(by=['tourney_level_factor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eeb05c-f7b8-4a2e-8166-a5d61548970c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2346de55eb8baa31e60af8b854d5f573",
     "grade": false,
     "grade_id": "cell-be2dd85a6878fd5d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### My Step 2: Compile a Data Frame of Players with Weighted Wins and Losses\n",
    "Using the previously obtained data frame, I compile a data frame of all the winners and the losers. I create a joint data frame of all the players by counting up all their won and lost games, weighting the games by tourney_level_factor. I add a column called points, which is each players wins minus some fraction of their losses. Then, I choose the BEST 5 players as those with the most points.\n",
    "\n",
    "(I had an I idea to compile a data frame of all the winners AND all the losers. Then join the win and lose dfs, and find the win and lose percentage for each player given the weighted game counts. Then the players with the highest win percentage are the best players. However, I found this to be an unfair estimate of BEST since if a player only played 1 game and won that 1 game, their win percentage woulld be 100. Nevertheless, I included this work below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2269b8-742e-452d-b562-ab7edcc8d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of all the wins\n",
    "df_wtd_winners = df_wtd.filter(['winner_id', 'winner_name', 'tourney_level', 'tourney_level_factor'])\n",
    "df_wtd_winners = df_wtd_winners.groupby(['winner_id', 'winner_name'])['tourney_level_factor'].sum().reset_index()\n",
    "df_wtd_winners.rename(columns={'winner_id':'id', 'winner_name':'name', 'tourney_level_factor':'wins'}, inplace=True)\n",
    "df_wtd_winners.sort_values(by=['wins'], ascending=False, inplace=True, ignore_index=True)\n",
    "# print(\"df_wtd_winners\")\n",
    "# display(df_wtd_winners.head())\n",
    "\n",
    "# Create a table of all the losses\n",
    "df_wtd_losses = df_wtd.filter(['loser_id', 'loser_name', 'tourney_level', 'tourney_level_factor'])\n",
    "df_wtd_losses = df_wtd_losses.groupby(['loser_id', 'loser_name'])['tourney_level_factor'].sum().reset_index()\n",
    "df_wtd_losses.rename(columns={'loser_id':'id', 'loser_name':'name', 'tourney_level_factor':'losses'}, inplace=True)\n",
    "# df_wtd_losses.sort_values(by=['losses'], ascending=True, inplace=True, ignore_index=True)\n",
    "# print(\"df_wtd_losses\")\n",
    "# display(df_wtd_losses)\n",
    "\n",
    "# Create a joint table of all players with their win and lose stats\n",
    "df_wtd_players = df_wtd_winners.merge(df_wtd_losses, 'outer').fillna(0)\n",
    "df_wtd_players['points'] = df_wtd_players['wins'] - (df_wtd_players['losses']/4)\n",
    "df_wtd_players.sort_values(by=['points'], ascending=False, inplace=True, ignore_index=True)\n",
    "print(\"My BEST Players\")\n",
    "display(df_wtd_players.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa5bf1-ea20-4bf2-923b-611ef73a0b66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2346de55eb8baa31e60af8b854d5f573",
     "grade": false,
     "grade_id": "cell-be2dd85a6878fd5d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### My Step 3: Compare to Original Rankings\n",
    "To see how well my ranking did, I compare to the original df rankings, choosing the most recent rank for each player.\n",
    "Then I compare the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09550f94-1bf3-4d23-b2c5-08534b3062ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to original df ranking\n",
    "# Find the players with the top rank, filtering out duplicate players by only keeping their rank from the most current date\n",
    "df_winners = df.filter(['winner_id', 'winner_name', 'winner_rank', 'year', 'month']).sort_values(by=['year', 'month', 'winner_rank'], ascending=[False, False, True])\n",
    "df_winners = df_winners.drop_duplicates(subset=['winner_name', 'winner_id'])\n",
    "df_winners.rename(columns={'winner_id':'id', 'winner_name':'name', 'winner_rank':'rank'}, inplace=True)\n",
    "df_winners.sort_values(by=['rank'], ascending=True, inplace=True, ignore_index=True)\n",
    "print(\"Original Top Ranked Players\")\n",
    "display(df_winners.head())\n",
    "\n",
    "# Of my BEST players, the Original Top Ranked Players is missing David Ferrer and Andy Murray. \n",
    "# Of the original Top Ranked Players, my BEST players are missing Dominic Thiem and Daniil Medvedev.\n",
    "# Let's find where they fell in each data frame\n",
    "print(\"Other Top Ranked Players Weighted Scores\")\n",
    "display(df_wtd_players[df_wtd_players['name'].isin(['Dominic Thiem', 'Daniil Medvedev'])])\n",
    "print(\"My Other BEST Players Original Ranks\")\n",
    "display(df_winners[df_winners['name'].isin(['Andy Murray', 'David Ferrer'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad66e2-5bf8-4c62-8bc5-ea53b424f755",
   "metadata": {
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2346de55eb8baa31e60af8b854d5f573",
     "grade": false,
     "grade_id": "cell-be2dd85a6878fd5d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### My Step 4: Conclusion\n",
    "I think my rankings did pretty well. In finding the BEST players I take into account tourney level, draw size, wins, and losses. My top 3 BEST players were consistent with the original top 3 highest ranked players.\n",
    "I believe my analysis may be flawed because there is probably a better way to take into account losses in the determination of BEST.\r",
    "I would want tto improvemyr analysi by factoring in losses better, though I don't know how I would do that. Just looking at the wins and losses data I think my analysis does a fine job of finding the BEST players.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23a18b-b05d-4114-9103-be5a4541deb4",
   "metadata": {},
   "source": [
    "#### Scrap Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984af91e-3325-4289-b15b-5a91bae576bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "RANKING SURFACES\n",
    "\n",
    "Another idea I had of how to decide 'BEST' is to take into account surface, but after research I found that it doesn't really contribute. I have kept my work below.\n",
    "\n",
    "https://matchpointpost.com/best-tennis-court-surface/\n",
    "\n",
    "https://www.tennisletics.com/blog/how-different-types-of-court-impact-a-tennis-match/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2e35d-d91d-45c3-8f31-928ad58fc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'surface':   ['Carpet', 'Clay', 'Grass', 'Hard'],\n",
    "        'speed':     ['fast', 'slow', 'fastest', 'medium'],\n",
    "        'bounce' :   ['low', 'high', 'low', 'medium']}\n",
    "\n",
    "surfaces = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e5336-a45f-4085-9ddd-7fc8a96adae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "FAULTY REASONING WIN PERCENTAGE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eeb3b4-7ccc-4c02-bedc-2e2ef82f841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of all the wins\n",
    "df_wins = df_wtd.filter(['winner_id', 'winner_name', 'tourney_level', 'tourney_level_factor'])\n",
    "df_wins = df_wins.groupby(['winner_id', 'winner_name'])['tourney_level_factor'].sum().reset_index()\n",
    "df_wins.rename(columns={'winner_id':'id', 'winner_name':'name', 'tourney_level_factor':'wins'}, inplace=True)\n",
    "# print(\"df_wins\")\n",
    "# display(df_wins.sort_values(by=['wins'], ascending=False))\n",
    "\n",
    "# Create a table of all the losses\n",
    "df_losses = df_wtd.filter(['loser_id', 'loser_name', 'tourney_level', 'tourney_level_factor'])\n",
    "df_losses = df_losses.groupby(['loser_id', 'loser_name'])['tourney_level_factor'].sum().reset_index()\n",
    "df_losses.rename(columns={'loser_id':'id', 'loser_name':'name', 'tourney_level_factor':'losses'}, inplace=True)\n",
    "# print(\"df_losses\")\n",
    "# display(df_losses.sort_values(by=['losses'], ascending=False))\n",
    "\n",
    "# Create a joint table of all players with their win and lose stats\n",
    "# add a column of win percentage and lose percentage\n",
    "df_players = df_wins.merge(df_losses, 'outer', sort=True).fillna(0)\n",
    "df_players['games'] = df_players['wins'] + df_players['losses']\n",
    "df_players['win_prc'] = (df_players['wins'] / df_players['games'] * 100).round(0).astype(int)\n",
    "df_players['lose_prc'] = (df_players['losses'] / df_players['games'] * 100).round(0).astype(int)\n",
    "df_players.sort_values(by='win_prc', ascending=False, inplace=True)\n",
    "# print(\"df_players\")\n",
    "# display(df_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec4b0c-ce55-42ca-8488-85f3db8adeed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "JUNK DRAWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d667494-0a10-4a5c-80fb-f5f572aa0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_tl_ds.to_string())\n",
    "\n",
    "# to get the amount of draw_size games per tourney level\n",
    "#df_tl_ds_size = df_tl_ds.groupby(['draw_size', 'tourney_level']).size().reset_index(name='count').sort_values(by=['tourney_level', 'draw_size'])\n",
    "  \n",
    "# display(df_wins.head())\n",
    "# display(df_losses.head())\n",
    "# print(\"df_players\")\n",
    "# display(df_players.head())\n",
    "# df_players.info()\n",
    "\n",
    "# df.info()\n",
    "# temp2 = temp.groupby([\"tourney_level\", \"winner_rank\"]).size().reset_index(name=\"count\")\n",
    "# display(temp, temp2)\n",
    "# print(temp.to_string())\n",
    "# temp2.groupby([\"tourney_level\"]).nsmallest(5).reset_index()\n",
    "# temp2.nlargest(5, \"winner_rank\", keep='all').sort_values(by=['tourney_level'])\n",
    "# df_tl_ds = df.filter([\"draw_size\", \"tourney_level\", \"winner_rank\", \"winner_name\", \"minutes\"]).sort_values(by=['draw_size'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
